# 甘蔗抓取计划

### 大致方案路线
1. 选取一个性能良好的目标检测模型，获得检测框数据 
2. 选取检测框包围的图像，投送给姿态检测模型获取关键点 
3. 根据关键点在图像的位置，配合深度图获得姿态点空间坐标 
4. 根据空间坐标实现对应的机械控制


RGB 图像
   ↓
YOLO 等目标检测（得到整体 ROI）
   ↓
ROI 裁剪 + resize
   ↓
关键点网络（输出热力图 heatmap）
   ↓
从 heatmap 中解码 2D 关键点
   ↓
映射回原图坐标系
   ↓
结合深度 → 3D 关键点
   ↓
计算整体位置 + 朝向 / 姿态


### 网络输出

YOLOv8 的分割模型输出主要包括以下两个部分：

**检测输出（Detections）**

- 包含每个检测到的目标的边界框（bounding box）、类别（class）、置信度（confidence）。
- 格式通常为一个二维张量（tensor），每一行为一个检测结果，包含 `[x1, y1, x2, y2, confidence, class, ...]`，其中 x1, y1, x2, y2 是边界框坐标。

**分割掩码输出（Segmentation Masks）**

- 对每个检测到的目标，模型还会输出一个分割掩码（mask），用于精确标记目标的像素区域。
- 掩码通常以张量形式输出，形状为 `[num_detections, mask_height, mask_width]`，每个掩码与对应的检测结果一一对应。
- 掩码的数值一般为概率（0~1），需要经过阈值处理（如 `>0.5`）才能得到二值化的分割结果。

**输出格式举例：**

- 检测输出（Detections）：`(num_detections, 6)`，如 `[x1, y1, x2, y2, confidence, class]`
- 分割掩码（Masks）：`(num_detections, mask_height, mask_width)`

其中 mask_height 和 mask_width 与输入图像的分辨率有关，mask_height 和 mask_width 通常为输入图像的宽度和高度的一半。后续需要自己测试一下。

在 Luxonis OAK 设备上，经过专用转换工具（如 tools-cli 或 simplified conversion 工具）转换后的 YOLOv8 分割模型，
其输出格式会被标准化，以便于直接用 DepthAI 的 DetectionNetwork 或 YOLOExtendedParser 节点进行解析和后处理。
这样可以实现边界框和分割掩码的同步输出，且无需在主机端手动解析原始张量。




### 最小可用系统（强烈推荐）
Step 1：语义 / 实例分割

类别：sugarcane_pile

输出：一个或多个 mask

Step 2：mask → 朝向

方法：PCA 或结构张量

输出：θ ∈ [0, π)

Step 3：全局融合（如需要）

面积加权方向平均

得到全局朝向